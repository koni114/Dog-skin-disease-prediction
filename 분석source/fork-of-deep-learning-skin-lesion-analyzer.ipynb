{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### 간략 정리\n* 사용자는 피부병 사진을 업로드하면, 지속적인 예측이 가능하도록 설계\n* 이 커널은 인간의 피부병을 분류하는 모델을 제작하는 커널\n* 총 7개의 피부병이 존재\n* 모델은 MobileNet CNN에서 fine tune을 사용\n* 이 커널에서 모든 모델은 training 됨\n* 주요 해결 포인트는 imblanced한 모델과 작은 양의 데이터\n* class imblanced를 해결하기 위해 augmentation 기법을 활용하여, 한쪽으로 편향된 accuracy score에서 벗어남\n* MobileNet은 small size고, 빨라 모델 실행 연동시 유리 --> 차후 알파도 팻케어 어플과 연동하기 위함\n\n### 모델 선정 전략\n* 이 커널은 모델 선정 전략에 있어 중요한 가이던스를 제공\n* 전체 accuracy는 60% 정도 일 수 있지만, top 3 accuracy에 대해서는 높은 정확률을 나타낼 수 있음  \n  이러한 모델은 꽤 좋은 모델이라고 생각할 수 있음"},{"metadata":{},"cell_type":"markdown","source":"#### 1. 필요한 라이브러리 로딩"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from numpy.random import seed\nseed(101)\n# from tensorflow  import set_random_seed\n# set_random_seed(101)\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nimport os\n\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Labels : 총 7개 class --> [Total images = 10015]\n* nv : Melanocytic nevi, 6705개\n* mel : Melanoma, 1113개\n* bkl : Benign keratosis, 1099개\n* bcc : Basal cell carcinoma, 514개\n* akiec : Actinic Keratoses, 327개\n* vasc : Vascular skin, 142개\n* df : Dermatofibroma, 115개[](http://)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.listdir('../input/skin-cancer-mnist-ham10000/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 디렉토리 구조 만들기\n* Keras generator에 사용하기 위한 directory 구조 설계\n* 다음과 같은 구조로 설계\n\n#### train_dir\n  * nv\n  * mel\n  * bkl\n  * bcc\n  * akiec\n  * vasc\n  * df\n  \n#### val_dir\n  * nv\n  * mel\n  * bkl\n  * bcc\n  * akiec\n  * vasc\n  * df"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = 'base_dir'\nos.mkdir(base_dir)\n\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\nnv = os.path.join(train_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(train_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(train_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(train_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(train_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(train_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(train_dir, 'df')\nos.mkdir(df)\n\nnv = os.path.join(val_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(val_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(val_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(val_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(val_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(val_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(val_dir, 'df')\nos.mkdir(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### train, validation set 만들기"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data = pd.read_csv('../input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\ndf_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 층별화된 validation set 만들기"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_data.groupby('lesion_id').count()\ndf = df[df['image_id'] == 1]\n\n# lesion_id 별 image가 1개만 있는 것들만 추출해서 확인\ndf.reset_index(inplace = True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lesion_id 별로 이미지가 여러개 있는 것들과, 오직 1개만 있는 것들 확인\ndef identify_duplicates(x):\n    \n    unique_list = list(df['lesion_id'])\n    \n    if x in unique_list:\n        return \"no_duplicates\"\n    else:\n        return \"has_duplicates\"\n    \ndf_data['duplicates'] = df_data['lesion_id']\ndf_data['duplicates'] = df_data['duplicates'].apply(identify_duplicates)\n\ndf_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data['duplicates'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 중복이 없는 unique한 image만 추출\n# validationSet에는 중복된 데이터가 없어야 하기 때문에 일부러 unique한 이미지만 filtering\n\ndf = df_data[df_data['duplicates'] == 'no_duplicates']\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터 수가 매우 적으므로, 전체 데이터 0.17%만 Test 데이터로 사용..\ny = df['dx']\n_, df_val = train_test_split(df, test_size = 0.17, random_state = 101, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 각 y label별 count를 확인해보면, nv가 압도적으로 많음. --> imblanced 한 데이터. & small data\ndf_val['dx'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### validationSet을 제외한 나머지 데이터로 train Dataset 만들기"},{"metadata":{"trusted":true},"cell_type":"code","source":"def identify_val_rows(x):\n    \n    val_list = list(df_val['image_id'])\n    \n    if str(x) in val_list:\n        return 'val'\n    else:\n        return 'train'\n    \n    \ndf_data['train_or_val'] = df_data['image_id']\ndf_data['train_or_val'] = df_data['train_or_val'].apply(identify_val_rows)\n\ndf_train = df_data[df_data['train_or_val'] == 'train']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df_train))\nprint(len(df_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['dx'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val['dx'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 이미지를 폴더로 전송하기"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_data의 index를 image_id로 setting\ndf_data.set_index('image_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2개 폴더의 directory 저장\nfolder_1 = os.listdir('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1')\nfolder_2 = os.listdir('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2')\n\n# train / validation의 image_id list 저장\ntrain_list = list(df_train['image_id'])\nval_list = list(df_val['image_id'])\n\n# train image 전송\nfor image in train_list:\n    fname = image + \".jpg\"\n    label = df_data.loc[image, 'dx']\n    \n    if fname in folder_1:\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1', fname)\n        dst = os.path.join(train_dir, label, fname)\n        shutil.copyfile(src, dst)\n        \n    if fname in folder_2:\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2', fname)\n        dst = os.path.join(train_dir, label, fname)\n        shutil.copyfile(src, dst)\n    \n\nfor image in val_list:\n    \n    fname = image + '.jpg'\n    label = df_data.loc[image,'dx']\n    \n    if fname in folder_1:\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1', fname)\n        dst = os.path.join(val_dir, label, fname)\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2', fname)\n        dst = os.path.join(val_dir, label, fname)\n        shutil.copyfile(src, dst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir('base_dir/train_dir/nv')))\nprint(len(os.listdir('base_dir/train_dir/mel')))\nprint(len(os.listdir('base_dir/train_dir/bkl')))\nprint(len(os.listdir('base_dir/train_dir/bcc')))\nprint(len(os.listdir('base_dir/train_dir/akiec')))\nprint(len(os.listdir('base_dir/train_dir/vasc')))\nprint(len(os.listdir('base_dir/train_dir/df')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir('base_dir/val_dir/nv')))\nprint(len(os.listdir('base_dir/val_dir/mel')))\nprint(len(os.listdir('base_dir/val_dir/bkl')))\nprint(len(os.listdir('base_dir/val_dir/bcc')))\nprint(len(os.listdir('base_dir/val_dir/akiec')))\nprint(len(os.listdir('base_dir/val_dir/vasc')))\nprint(len(os.listdir('base_dir/val_dir/df')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### aug_dir 디렉토리로 train dataSet 복사"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_list = ['mel','bkl','bcc','akiec','vasc','df']\n\nfor item in class_list:\n    \n    # aug_dir directory 생성\n    aug_dir = 'aug_dir'\n    if not(os.path.isdir(aug_dir)): \n        os.mkdir(aug_dir)\n    \n    # aug_dir/img_dir directory 생성\n    img_dir = os.path.join (aug_dir, 'img_dir')\n    if not(os.path.isdir(img_dir)): \n        os.mkdir(img_dir)\n    \n    # label class 명 저장\n    img_class = item\n    \n    # img_list -> 기존 trainDataset에 있는 image dataList \n    img_list = os.listdir('base_dir/train_dir/' + img_class)\n    \n    # img_list 를 aug_dir/img_dir/class명/ directory 에 복사\n    for fname in img_list:\n        src = os.path.join('base_dir/train_dir/' + img_class, fname)\n        dst = os.path.join(img_dir, fname)\n        shutil.copyfile(src, dst)\n        \n    path = aug_dir\n    save_path = 'base_dir/train_dir/' + img_class\n    \n    # augmentation을 위한 ImageDataGenerator 생성\n    datagen = ImageDataGenerator(\n        rotation_range    = 180,\n        width_shift_range = 0.1,\n        height_shift_range= 0.1,\n        zoom_range        = 0.1,\n        horizontal_flip   = True,\n        vertical_flip     = True,\n        fill_mode         ='nearest')\n    # batch_size --> 50\n    batch_size = 50\n    \n    # flow_from_directory function을 통한 batch_size 지정\n    aug_datagen = datagen.flow_from_directory(path,\n                                           save_to_dir = save_path,\n                                           save_format = 'jpg',\n                                           target_size = (224,224),\n                                           batch_size  = batch_size)\n    \n    # label당 총 augmenation image 개수를 6000로 대충 맞추고 싶음\n    \n    num_aug_images_wanted = 6000\n    num_files  = len(os.listdir(img_dir))\n    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))  \n    \n    for i in range(0,num_batches):\n            imgs, labels = next(aug_datagen)\n            \n    shutil.rmtree('aug_dir')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 증식된 데이터를 포함함 trainDataSet 확인\nprint(len(os.listdir('base_dir/train_dir/nv')))\nprint(len(os.listdir('base_dir/train_dir/mel')))\nprint(len(os.listdir('base_dir/train_dir/bkl')))\nprint(len(os.listdir('base_dir/train_dir/bcc')))\nprint(len(os.listdir('base_dir/train_dir/akiec')))\nprint(len(os.listdir('base_dir/train_dir/vasc')))\nprint(len(os.listdir('base_dir/train_dir/df')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 50개의 증식된 이미지 시각화"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3):\n            ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    \n    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        if titles is not None:\n            sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n        \nplots(imgs, titles=None) # titles=labels will display the image labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### generator set up 하기"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = 'base_dir/train_dir'\nvalid_path = 'base_dir/val_dir'\n\nnum_train_samples = len(df_train)  # train dataset 개수\nnum_val_samples   = len(df_val)    # val dataset 개수\ntrain_batch_size  = 10             # train batch size : 10\nval_batch_size    = 10             # val batch size   : 10\nimage_size        = 224            # image_size       : 224,\n\ntrain_steps       = np.ceil(num_train_samples / train_batch_size)\nval_steps         = np.ceil(num_val_samples / val_batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    preprocessing_function = \\\n     tensorflow.keras.applications.mobilenet.preprocess_input)\n\ntrain_batches = datagen.flow_from_directory(\n        train_path,                             # train image가 있는 path\n        target_size = (image_size, image_size), # image_size\n        batch_size  = train_batch_size)\n\nvalid_batches = datagen.flow_from_directory(\n         valid_path,                             # train image가 있는 path\n        target_size = (image_size, image_size),  # image_size\n        batch_size  = val_batch_size)\n\n\n# test dataset은 shuffle 되면 안되므로, shuffle = False.\ntest_batches = datagen.flow_from_directory(\n            valid_path,\n            target_size = (image_size,image_size),\n            batch_size  = 1,\n            shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MobileNet 수정하기"},{"metadata":{"trusted":true},"cell_type":"code","source":"mobile = tensorflow.keras.applications.mobilenet.MobileNet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mobile.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(mobile.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mobileNet이 가지고 있는 layer 수 : 93\nlen(mobile.layers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### fine tuning.\n* 마지막 5개 layer 제거\n* global_average_pooling2d_1 를 포함한 모든 레이어를 포함시킴\n* 마지막 dense layer의 class --> 7\n* 0.25 값의 dropout 포함시킴"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = mobile.layers[-6].output\nx = Dropout(0.25)(x)\n\npredictions  = Dense(7, activation = 'softmax')(x)\nmodel = Model(inputs = mobile.input, outputs = predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 훈련시킬 layer를 설정해야 함\n# 마지막 23개의 layer를 제외한 나머지  weights를 freezing.\n\nfor layer in model.layers[:-23]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### model training 시키기"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy \n\ndef top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k = 3)\n\ndef top_2_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(Adam(lr=0.01), loss = 'categorical_crossentropy',\n             metrics = [categorical_accuracy, top_2_accuracy, top_3_accuracy]\n             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### model 생성\n* melanoma에 좀 더 민감하도록 모델 생성"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(valid_batches.class_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = {\n    0: 1.0,\n    1: 1.0,\n    2: 1.0,\n    3: 1.0,\n    4: 3.0,\n    5: 1.0,\n    6: 1.0,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath   = \"model.h5\"\ncheckpoint = ModelCheckpoint(  filepath, monitor = 'val_top_3_accuracy'\n                             , verbose = 1\n                             , save_best_only =  True\n                             , mode = 'max') \n\n# 검증 손실이 줄어들지 않을 때 학습률을 작게 조정할 수 있음.\nreduce_lr = ReduceLROnPlateau( monitor = 'val_top_3_accuracy'\n                              , factor = 0.5\n                              , patience = 2\n                              , verbose = 1\n                              , mode = 'max'\n                              , min_lr = 0.00001)\n\ncallbacks_list = [checkpoint, reduce_lr]\n\nhistory = model.fit_generator(\n        train_batches,\n        steps_per_epoch = train_steps,\n        class_weight    = class_weights,\n        validation_data = valid_batches,\n        validation_steps = val_steps,\n        epochs = 30,\n        verbose = 1,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.metrics_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# 마지막 epoch를 수행한 모델의 가중치 사용\n\nval_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\nmodel.evaluate_generator(test_batches\n                         , steps = len(df_val))\n\nprint('val_loss', val_loss)\nprint('val_cat_acc', val_cat_acc)\nprint('val_top_2_acc:', val_top_2_acc)\nprint('val_top_3_acc:', val_top_3_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best epoch를 수행한 모델의 가중치 사용\n\nmodel.load_weights('model.h5')\nval_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\nmodel.evaluate_generator(test_batches, \n                        steps=len(df_val))\n\nprint('val_loss:', val_loss)\nprint('val_cat_acc:', val_cat_acc)\nprint('val_top_2_acc:', val_top_2_acc)\nprint('val_top_3_acc:', val_top_3_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### training curve plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\ntrain_top2_acc = history.history['top_2_accuracy']\nval_top2_acc = history.history['val_top_2_accuracy']\ntrain_top3_acc = history.history['top_3_accuracy']\nval_top3_acc = history.history['val_top_3_accuracy']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, 'bo', label='Training cat acc')\nplt.plot(epochs, val_acc, 'b', label='Validation cat acc')\nplt.title('Training and validation cat accuracy')\nplt.legend()\nplt.figure()\n\n\nplt.plot(epochs, train_top2_acc, 'bo', label='Training top2 acc')\nplt.plot(epochs, val_top2_acc, 'b', label='Validation top2 acc')\nplt.title('Training and validation top2 accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, train_top3_acc, 'bo', label='Training top3 acc')\nplt.plot(epochs, val_top3_acc, 'b', label='Validation top3 acc')\nplt.title('Training and validation top3 accuracy')\nplt.legend()\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels  = test_batches.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batches.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test data에 대한 prediction값 출력\npredictions = model.predict_generator(test_batches, steps=len(df_val), verbose=1)\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(test_labels, predictions.argmax(axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batches.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the labels of the class indices. These need to match the \n# order shown above.\ncm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 다차원 배열의 경우에 차원에 따라 가장 큰 값의 인덱스들을 반환해주는 함수\n# test image에 대한 가장 큰 확률 값 return\ny_pred = np.argmax(predictions, axis=1)\n\n# Get the labels of the test images.\ny_true = test_batches.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n\nprint(report)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}